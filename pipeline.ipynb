{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Load grocery_sales.csv into a DataFrame\n",
        "grocery_sales = pd.read_csv(\"grocery_sales.csv\")"
      ],
      "metadata": {
        "id": "sUKNog63eqJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOapzlhgdOsn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Extract function is already implemented for you\n",
        "def extract(store_data, extra_data):\n",
        "    extra_df = pd.read_parquet(extra_data)\n",
        "    merged_df = store_data.merge(extra_df, on=\"index\")\n",
        "    return merged_df\n",
        "\n",
        "# Call the extract function with grocery_sales DataFrame\n",
        "merged_df = extract(grocery_sales, \"extra_data.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the transform() function with one parameter: \"raw_data\"\n",
        "import pandas as pd\n",
        "\n",
        "def transform(raw_data):\n",
        "    # Identify columns with missing values\n",
        "    missing_columns = raw_data.columns[raw_data.isnull().any()]\n",
        "\n",
        "    for column in missing_columns:\n",
        "        # Check if the column is of numerical type\n",
        "        if raw_data[column].dtype in ['float64', 'int64']:\n",
        "            # Fill numerical columns with the mean for most cases\n",
        "            mean_value = raw_data[column].mean()\n",
        "            raw_data[column].fillna(mean_value, inplace=True)\n",
        "\n",
        "        # Check if the column is categorical (object or category types)\n",
        "        elif raw_data[column].dtype in ['object', 'category']:\n",
        "            # Fill categorical columns with the mode (most frequent value)\n",
        "            mode_value = raw_data[column].mode()[0]\n",
        "            raw_data[column].fillna(mode_value, inplace=True)\n",
        "\n",
        "        # Check if the column is of datetime type\n",
        "        elif pd.api.types.is_datetime64_any_dtype(raw_data[column]):\n",
        "            # Fill datetime columns using forward fill\n",
        "            raw_data[column].fillna(method=\"ffill\", inplace=True)\n",
        "\n",
        "    # Remove rows where Weekly_Sales is not greater than 10,000\n",
        "    raw_data = raw_data[raw_data[\"Weekly_Sales\"] > 10000]\n",
        "\n",
        "    # Add a \"Month\" column extracted from the \"Date\" column\n",
        "    raw_data[\"Month\"] = pd.to_datetime(raw_data[\"Date\"]).dt.month\n",
        "\n",
        "    # Drop unnecessary columns (you can adjust this as per your specific needs)\n",
        "    columns_to_drop = ['level_0_x', 'level_0_y', 'index', 'Type', 'Size','Temperature','Fuel_Price','MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5','Date']\n",
        "    raw_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
        "   # raw_data.rename(columns={\"Weekly_Sales\": \"Avg_Sales\"}, inplace=True)\n",
        "    # Return the cleaned DataFrame\n",
        "    clean_data = raw_data\n",
        "    return clean_data"
      ],
      "metadata": {
        "id": "AvKRW8RmeBFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the transform() function and pass the merged DataFrame\n",
        "clean_data = transform(merged_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itAgmuxGfBON",
        "outputId": "3cf1965d-955f-434f-905e-7d5cb666882c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-a27748f8de80>:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  raw_data[column].fillna(mode_value, inplace=True)\n",
            "<ipython-input-6-a27748f8de80>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  raw_data[column].fillna(mean_value, inplace=True)\n",
            "<ipython-input-6-a27748f8de80>:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  raw_data[\"Month\"] = pd.to_datetime(raw_data[\"Date\"]).dt.month\n",
            "<ipython-input-6-a27748f8de80>:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  raw_data.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the avg_weekly_sales_per_month function that takes in the cleaned data from the last step\n",
        "def avg_weekly_sales_per_month(clean_data):\n",
        "    agg_data=clean_data.groupby([\"Month\"]).agg(Avg_Sales=(\"Weekly_Sales\",\"mean\")).reset_index().round(2)\n",
        "    return agg_data"
      ],
      "metadata": {
        "id": "N9ylYnXofDw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the avg_weekly_sales_per_month() function and pass the cleaned DataFrame\n",
        "agg_data = avg_weekly_sales_per_month(clean_data)"
      ],
      "metadata": {
        "id": "4VUg5FBCfHIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the load() function that takes in the cleaned DataFrame and the aggregated one with the paths where they are going to be stored\n",
        "def load(cleaned_data, agg_data, cleaned_path, agg_path):\n",
        "    # Save the cleaned data to a CSV file without the index\n",
        "    cleaned_data.to_csv(cleaned_path, index=False)\n",
        "\n",
        "    # Save the aggregated data to a CSV file without the index\n",
        "    agg_data.to_csv(agg_path, index=False)"
      ],
      "metadata": {
        "id": "p7K_QjZyfKMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the load() function and pass the cleaned and aggregated DataFrames with their paths\n",
        "load(clean_data, agg_data, \"clean_data.csv\", \"agg_data.csv\")"
      ],
      "metadata": {
        "id": "Iyh1cGdsfMnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the validation() function with one parameter: file_path - to check whether the previous function was correctly executed\n",
        "def validation(path):\n",
        "    # Check if the cleaned data CSV file exists\n",
        "    if os.path.exists(path):\n",
        "        print(f\"{path} exists.\")\n",
        "    else:\n",
        "        print(f\"{path} does not exist.\")"
      ],
      "metadata": {
        "id": "z5WIe_V1fPEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the validation() function and pass first, the cleaned DataFrame path, and then the aggregated DataFrame path\n",
        "validation(\"clean_data.csv\")\n",
        "validation(\"agg_data.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGC3IKsefR8B",
        "outputId": "0b8bef3c-e636-4079-c6a5-63ef77e98d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clean_data.csv exists.\n",
            "agg_data.csv exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UgKFxHpSfUZa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}